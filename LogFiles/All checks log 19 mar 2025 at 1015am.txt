(spark_ikart_env) akshay@LAPTOP-OTII9OR8:~/project$ python main.py
INFO:root:Successfully loaded database configuration.
INFO:root:Detected Encoding: ascii
INFO:root:Detected Delimiter: ,
25/03/19 04:36:48 WARN Utils: Your hostname, LAPTOP-OTII9OR8 resolves to a loopback address: 127.0.1.1; using 172.20.69.108 instead (on interface eth0)
25/03/19 04:36:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/03/19 04:36:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
INFO:root:Spark session created successfully.
INFO:root:Encoding found : ascii                                                
INFO:root:Delimiter found : ,
INFO:root:Data loaded successfully.
INFO:root:Row count: 2805307                                                    
WARNING:root:check_store_location check FAILED.                                 
INFO:root:check_unique_invoice check PASSED.
INFO:root:check_date_format check PASSED.
INFO:root:check_sale_dollars check PASSED.
INFO:root:check_bottles_sold check PASSED.
INFO:root:Bad records found. Good: 2474972 | Bad: 330335                        
INFO:root:Writing 330335 records to parquet file at /home/akshay/bad_records.parquet
INFO:root:Bad records successfully written to: /home/akshay/bad_records.parquet 
root
 |-- invoice_and_item_number: string (nullable = true)
 |-- date: date (nullable = true)
 |-- store_number: integer (nullable = true)
 |-- store_name: string (nullable = true)
 |-- address: string (nullable = true)
 |-- city: string (nullable = true)
 |-- zip_code: double (nullable = true)
 |-- store_location: string (nullable = true)
 |-- county_number: integer (nullable = true)
 |-- county: string (nullable = true)
 |-- category: double (nullable = true)
 |-- category_name: string (nullable = true)
 |-- vendor_number: double (nullable = true)
 |-- vendor_name: string (nullable = true)
 |-- item_number: integer (nullable = true)
 |-- item_description: string (nullable = true)
 |-- pack: integer (nullable = true)
 |-- bottle_volume_ml: integer (nullable = true)
 |-- state_bottle_cost: double (nullable = true)
 |-- state_bottle_retail: double (nullable = true)
 |-- bottles_sold: integer (nullable = true)
 |-- sale_dollars: double (nullable = true)
 |-- volume_sold_liters: double (nullable = true)
 |-- volume_sold_gallons: double (nullable = true)

INFO:root:Good Records Schema:None
INFO:root:Good Records Count: 2474972                                           
INFO:root:Checking if table public.iowa_liquor_sales exists in PostgreSQL.
INFO:root:Writing 2474972 records to PostgreSQL table: public.iowa_liquor_sales 
INFO:root:Good records successfully written to PostgreSQL!                      
INFO:root:ETL pipeline completed successfully!
INFO:py4j.clientserver:Closing down clientserver connection
(spark_ikart_env) akshay@LAPTOP-OTII9OR8:~/project$ ruff check
All checks passed!
(spark_ikart_env) akshay@LAPTOP-OTII9OR8:~/project$ pytest test_etl.py -v -s
====================================================== test session starts ======================================================
platform linux -- Python 3.12.3, pytest-8.3.5, pluggy-1.5.0 -- /home/akshay/spark_ikart_env/bin/python3
cachedir: .pytest_cache
rootdir: /home/akshay/project
plugins: anyio-4.9.0
collected 4 items                                                                                                               

test_etl.py::test_load_data 25/03/19 04:40:22 WARN Utils: Your hostname, LAPTOP-OTII9OR8 resolves to a loopback address: 127.0.1.1; using 172.20.69.108 instead (on interface eth0)
25/03/19 04:40:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/03/19 04:40:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/03/19 04:40:26 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.
PASSED                                                                          
PASSED                                                                          
PASSED                                                                          
root                                                                            
 |-- invoice_and_item_number: string (nullable = true)
 |-- date: date (nullable = true)
 |-- store_number: integer (nullable = true)
 |-- store_name: string (nullable = true)
 |-- address: string (nullable = true)
 |-- city: string (nullable = true)
 |-- zip_code: double (nullable = true)
 |-- store_location: string (nullable = true)
 |-- county_number: integer (nullable = true)
 |-- county: string (nullable = true)
 |-- category: double (nullable = true)
 |-- category_name: string (nullable = true)
 |-- vendor_number: double (nullable = true)
 |-- vendor_name: string (nullable = true)
 |-- item_number: integer (nullable = true)
 |-- item_description: string (nullable = true)
 |-- pack: integer (nullable = true)
 |-- bottle_volume_ml: integer (nullable = true)
 |-- state_bottle_cost: double (nullable = true)
 |-- state_bottle_retail: double (nullable = true)
 |-- bottles_sold: integer (nullable = true)
 |-- sale_dollars: double (nullable = true)
 |-- volume_sold_liters: double (nullable = true)
 |-- volume_sold_gallons: double (nullable = true)

PASSED                                                                          

======================================================= warnings summary ========================================================
../spark_ikart_env/lib/python3.12/site-packages/great_expectations/data_context/types/base.py:1635
  /home/akshay/spark_ikart_env/lib/python3.12/site-packages/great_expectations/data_context/types/base.py:1635: ChangedInMarshmallow4Warning: `Number` field should not be instantiated. Use `Integer`, `Float`, or `Decimal` instead.
    config_version = fields.Number(

../spark_ikart_env/lib/python3.12/site-packages/great_expectations/data_context/types/base.py:2687
  /home/akshay/spark_ikart_env/lib/python3.12/site-packages/great_expectations/data_context/types/base.py:2687: ChangedInMarshmallow4Warning: `Number` field should not be instantiated. Use `Integer`, `Float`, or `Decimal` instead.
    config_version = fields.Number(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================================== 4 passed, 2 warnings in 293.51s (0:04:53) ===========================================
(spark_ikart_env) akshay@LAPTOP-OTII9OR8:~/project$ 